{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3360513, 24), (3360513,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_chroma_vectors = np.load('data/01_all_chroma_vectors.npy')\n",
    "all_chord_labels = np.load('data/01_all_chord_labels.npy')\n",
    "all_chroma_vectors.shape, all_chord_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bit of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "counts, _, _ = plt.hist(all_chord_labels, bins=list(set(all_chord_labels)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22911.0, 408735.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(counts), max(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since minimum counts is ~20000, w/c is already a lot, we can get maybe around 1000 from each class as test set, 4000 from each class as validation set on 5 different splits, splits w/o overlapping data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 6, 3, 7, 4, 9, 8, 1, 2],\n",
       " [55, 66, 33, 77, 44, 99, 88, 11, 22],\n",
       " [4, 5, 2, 6, 3, 8, 7, 0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "_SEED = 0\n",
    "\n",
    "# test; must always return same result in successive runs\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(x)\n",
    "\n",
    "# re-seeding allows to get similar shuffles for diff.arrays\n",
    "y = [11,22,33,44,55,66,77,88,99]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(y)\n",
    "\n",
    "z = [0,1,2,3,4,5,6,7,8]\n",
    "rng = default_rng(seed=_SEED)\n",
    "rng.shuffle(z)\n",
    "\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 6, 3, 7, 4, 9, 8, 1, 2],\n",
       " [55, 66, 33, 77, 44, 99, 88, 11, 22],\n",
       " [4, 5, 2, 6, 3, 8, 7, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_set(array_set):\n",
    "    \"\"\" Shuffle in unison all arrays in array_set \"\"\"\n",
    "    for arr in array_set:\n",
    "        rng = default_rng(seed=_SEED)\n",
    "        rng.shuffle(arr)\n",
    "    \n",
    "    return array_set\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "y = [11,22,33,44,55,66,77,88,99]\n",
    "z = [0,1,2,3,4,5,6,7,8]\n",
    "x,y,z = shuffle_set((x,y,z))\n",
    "\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle first before splitting to add some randomness in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_NUM_TEST_PER_CLASS = 1 #1000\n",
    "_NUM_VAL_PER_CLASS = 4 #4000\n",
    "_NUM_VAL_SPLITS = 5\n",
    "\n",
    "class QueueData():\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.st_ix = 0\n",
    "    \n",
    "    def take(self, num):\n",
    "        st, ed = self.st_ix, self.st_ix+num\n",
    "        queue_out = tuple(data[st:ed] for data in self.dataset)\n",
    "        self.st_ix = ed\n",
    "        return queue_out\n",
    "    \n",
    "    def flush(self):\n",
    "        st, ed = self.st_ix, len(self.dataset[0])\n",
    "        queue_out = tuple(data[st:ed] for data in self.dataset)\n",
    "        return queue_out\n",
    "\n",
    "class SplitData():\n",
    "    def __init__(self, feats=None, labels=None):\n",
    "        self.feats = feats\n",
    "        self.labels = labels\n",
    "        \n",
    "    def push(self, feats, labels):\n",
    "        assert(len(feats)==len(labels))\n",
    "        if self.feats is None:\n",
    "            self.feats = feats\n",
    "        else:\n",
    "            self.feats = np.concatenate((self.feats, feats))\n",
    "        \n",
    "        if self.labels is None:\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.labels = np.concatenate((self.labels, labels))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (self.feats.shape, self.labels.shape)\n",
    "\n",
    "def get_splits(feats, labels, validate=True):\n",
    "    \"\"\" Return training, validation, and test sets \"\"\"\n",
    "    classes = list(set(labels))\n",
    "    classes.sort()\n",
    "    \n",
    "    if validate:\n",
    "        hist, _ = np.histogram(labels, bins=classes)\n",
    "        assert(min(hist) >= (_NUM_TEST_PER_CLASS + (_NUM_VAL_SPLITS*_NUM_VAL_PER_CLASS)))\n",
    "    \n",
    "    test_split = SplitData()\n",
    "    val_splits = [SplitData() for i in range(_NUM_VAL_SPLITS)]\n",
    "    train_split = SplitData()\n",
    "    \n",
    "    for cls in classes:\n",
    "        mask = (labels==cls)\n",
    "        queue = QueueData(dataset=(feats[mask], labels[mask]))\n",
    "        \n",
    "        test_split.push(*queue.take(_NUM_TEST_PER_CLASS))\n",
    "        for ix in range(_NUM_VAL_SPLITS):\n",
    "            val_splits[ix].push(*queue.take(_NUM_VAL_PER_CLASS))\n",
    "        train_split.push(*queue.flush())\n",
    "\n",
    "    return train_split, val_splits, test_split\n",
    "\n",
    "train_split, val_splits, test_split = get_splits(all_chroma_vectors[:100], all_chord_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((58, 24), (58,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((8, 24), (8,))\n",
      "((2, 24), (2,))\n"
     ]
    }
   ],
   "source": [
    "print(train_split.shape)\n",
    "for val_split in val_splits:\n",
    "    print(val_split.shape)\n",
    "print(test_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2835513, 24), (2835513,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((100000, 24), (100000,))\n",
      "((25000, 24), (25000,))\n"
     ]
    }
   ],
   "source": [
    "_NUM_TEST_PER_CLASS = 1000\n",
    "_NUM_VAL_PER_CLASS = 4000\n",
    "_NUM_VAL_SPLITS = 5\n",
    "\n",
    "all_chroma_vectors, all_chord_labels = shuffle_set((all_chroma_vectors, all_chord_labels))\n",
    "train_split, val_splits, test_split = get_splits(all_chroma_vectors, all_chord_labels)\n",
    "\n",
    "print(train_split.shape)\n",
    "for val_split in val_splits:\n",
    "    print(val_split.shape)\n",
    "print(test_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n"
     ]
    }
   ],
   "source": [
    "def get_next_cv_split(train_split, val_splits):\n",
    "    num_cv = len(val_splits)\n",
    "    for v_ix in range(num_cv): # index of val split at a specific round\n",
    "        addl_train_splits = val_splits[0:v_ix] + val_splits[v_ix+1:]\n",
    "        val_split = val_splits[v_ix]\n",
    "        \n",
    "        full_train_feats = np.concatenate((train_split.feats,\n",
    "                                           *[split.feats for split in addl_train_splits]))\n",
    "        full_train_labels = np.concatenate((train_split.labels,\n",
    "                                            *[split.labels for split in addl_train_splits]))\n",
    "        full_train_split = SplitData(feats=full_train_feats,labels=full_train_labels)\n",
    "        yield full_train_split, val_split\n",
    "            \n",
    "        \n",
    "for train, val in get_next_cv_split(train_split, val_splits):\n",
    "    print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the dataloader module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features and labels.\n",
      "Split into train, val, test.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import SimpleChromaDataset\n",
    "\n",
    "ds = SimpleChromaDataset(feat_label_files=('data/01_all_chroma_vectors.npy',\n",
    "                                           'data/01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n",
      "3235513 100000\n"
     ]
    }
   ],
   "source": [
    "for train, val in ds.get_next_cv_split():\n",
    "    print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features and labels.\n",
      "Split into train, val, test.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import SimpleChromaDataset\n",
    "\n",
    "ds = SimpleChromaDataset(feat_label_files=('data/01_all_chroma_vectors.npy',\n",
    "                                           'data/01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def K_plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SEED = 0\n",
    "_EPOCHS = 2 #10\n",
    "_BATCH_SIZE = 32 #512\n",
    "_CKPT_PATH = 'models/simple-chroma-{cv}'\n",
    "\n",
    "def init_simple_model(base_linear_units=256, dropout=0.6):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(units=base_linear_units, activation='relu'),\n",
    "        layers.Dropout(rate=dropout),\n",
    "        layers.Dense(units=base_linear_units*4, activation='relu'),\n",
    "        layers.Dropout(rate=dropout),\n",
    "        layers.Dense(units=base_linear_units, activation='relu'),\n",
    "        layers.Dense(units=ds.n_class),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# cross validation loop\n",
    "tf.random.set_seed(_SEED)\n",
    "for cv_ix, (train, val) in enumerate(ds.get_next_cv_split()):\n",
    "    print(f'----------- CV{cv_ix+1} -----------')\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                   .take(100) \\\n",
    "                                   .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                   .batch(_BATCH_SIZE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                 .take(100) \\\n",
    "                                 .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                 .batch(_BATCH_SIZE)\n",
    "    \n",
    "    model = init_simple_model()\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS)\n",
    "    \n",
    "    # get F1 score\n",
    "    pred_chord_ixs = np.argmax(model.predict(val.feats, batch_size=_BATCH_SIZE), axis=-1)\n",
    "    print(f\"val_fscore: {f1_score(y_true=val.labels, y_pred=pred_chord_ixs, average='macro')}\")\n",
    "    K_plot_loss(histstory)\n",
    "          \n",
    "    model.save(_CKPT_PATH.format(cv=cv_ix))\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03958175703883171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               6400      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                6425      \n",
      "=================================================================\n",
      "Total params: 538,393\n",
      "Trainable params: 538,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "m = tf.keras.models.load_model(_CKPT_PATH.format(cv=0))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "# add tuning\n",
    "# mind the seeding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
