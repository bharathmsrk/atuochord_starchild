{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons\n",
    "!pip install mir_eval\n",
    "!pip install hyperopt\n",
    "!pip install guildai # restart after install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab prep\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/colab-handover/autochord/chordseq/* ./\n",
    "!cp /content/drive/MyDrive/colab-handover/autochord/*.py ./\n",
    "!cp /content/drive/MyDrive/colab-handover/autochord/*.csv ./\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "base_dir = 'data/McGill-Billboard'\n",
    "data_index = 'billboard-2.0-manychords.csv'\n",
    "\n",
    "df_songs = pd.read_csv(f'{base_dir}/{data_index}')\n",
    "#df_songs = pd.read_csv(f'{data_index}') # colab\n",
    "df_songs.set_index('id', inplace=True)\n",
    "len(df_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>no_chord_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I Don't Mind</td>\n",
       "      <td>James Brown</td>\n",
       "      <td>0.049747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You've Got A Friend</td>\n",
       "      <td>Roberta Flack,Donny Hathaway</td>\n",
       "      <td>0.050770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Rose</td>\n",
       "      <td>Bette Midler</td>\n",
       "      <td>0.117244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                        artist  no_chord_percent\n",
       "id                                                                     \n",
       "3          I Don't Mind                   James Brown          0.049747\n",
       "4   You've Got A Friend  Roberta Flack,Donny Hathaway          0.050770\n",
       "6              The Rose                  Bette Midler          0.117244"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = [1289, 736, 637, 270, 18] # songs to exclude for testing\n",
    "df_dataset = df_songs.drop(index=test_ids)\n",
    "len(df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1167,    6,  986,  227,  743,  568,  107,  181,   27,  793])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "_SEED = 0\n",
    "\n",
    "df_idxs = np.array(df_dataset.index.values)\n",
    "rng = np.random.default_rng(_SEED)\n",
    "rng.shuffle(df_idxs)\n",
    "\n",
    "df_idxs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sequence data.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import ChromaSequenceDataset\n",
    "# import dataloader\n",
    "# from importlib import reload\n",
    "# reload(dataloader)\n",
    "\n",
    "_LABEL_TYPE = 'majmin'\n",
    "_SEQ_LEN = 64\n",
    "\n",
    "pre_computed_seq = f'data/chordseq/{_LABEL_TYPE}_{_SEQ_LEN}.pkl'\n",
    "#pre_computed_seq = f'{_LABEL_TYPE}_{_SEQ_LEN}.pkl' # colab\n",
    "ds = ChromaSequenceDataset(pre_computed_sequence=pre_computed_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((43541, 64, 24), (43541, 64)) ((6882, 64, 24), (6882, 64))\n",
      "((43575, 64, 24), (43575, 64)) ((6848, 64, 24), (6848, 64))\n",
      "((43448, 64, 24), (43448, 64)) ((6975, 64, 24), (6975, 64))\n",
      "((43485, 64, 24), (43485, 64)) ((6938, 64, 24), (6938, 64))\n",
      "((42843, 64, 24), (42843, 64)) ((7580, 64, 24), (7580, 64))\n"
     ]
    }
   ],
   "source": [
    "for train_split, val_split in ds.get_next_cv_split(df_idxs):\n",
    "    print(train_split.shape, val_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def K_plot_loss(history):\n",
    "    plt.plot(history.history['crf_loss'])\n",
    "    plt.plot(history.history['val_crf_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import _CHROMA_FEAT_NAMES, _MAJMIN_CLASSES\n",
    "# import model\n",
    "# from importlib import reload\n",
    "# reload(model)\n",
    "from model import ModelWithCRFLoss\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "_SEQ_LEN = 64\n",
    "\n",
    "def init_bilstm_crf_model(base_linear_units=256, dropout=0.6, opt='adam', lr=0.01):\n",
    "    input_ph = tf.keras.Input(shape=(_SEQ_LEN, len(_CHROMA_FEAT_NAMES),))\n",
    "    lstm_out = layers.Bidirectional(\n",
    "        layers.LSTM(units=base_linear_units, dropout=dropout,\n",
    "                    return_sequences=True, stateful=False),\n",
    "        merge_mode='concat')(input_ph)\n",
    "    crf_out = tfa.layers.CRF(units=len(_MAJMIN_CLASSES))(lstm_out)\n",
    "    model = Model(input_ph, crf_out)\n",
    "    model = ModelWithCRFLoss(model, dtype='float64')\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_bilstm_crf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 24)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64, 512)           575488    \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    [(None, 64), (None, 64, 2 13500     \n",
      "=================================================================\n",
      "Total params: 588,988\n",
      "Trainable params: 588,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, 64), (None, 64, 25), (None,), (25, 25)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.summary()\n",
    "model.base_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SEED = 0\n",
    "_EPOCHS = 2 #10\n",
    "_BATCH_SIZE = 2 #512\n",
    "_CKPT_PATH = 'models/chroma-seq-bilstm-crf-{cv}'\n",
    "\n",
    "def sample_train_loop(ds, ref_idxs):\n",
    "    # cross validation loop\n",
    "    tf.random.set_seed(_SEED)\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split(ref_idxs)):\n",
    "        print(f'----------- CV{cv_ix+1} -----------')\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                       .take(100) \\\n",
    "                                       .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                       .batch(_BATCH_SIZE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                     .take(100) \\\n",
    "                                     .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                     .batch(_BATCH_SIZE)\n",
    "\n",
    "        print(f'Num train: {len(train)}, Num val: {len(val)}')\n",
    "        assert(train.feats.shape[1:] == val.feats.shape[1:])\n",
    "        print(f'Input features: {train.feats.shape[1:]}, Num classes: {len(_MAJMIN_CLASSES)}')\n",
    "\n",
    "        model = init_bilstm_crf_model()\n",
    "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS)\n",
    "\n",
    "        # get acc\n",
    "        preds, _, _, _ = model.predict(val_split.feats, batch_size=_BATCH_SIZE)\n",
    "        acc = accuracy_score(val_split.labels.flatten(), preds.flatten())\n",
    "        print(f'Acc: {acc}')\n",
    "        K_plot_loss(history)\n",
    "\n",
    "        #model.save(_CKPT_PATH.format(cv=cv_ix))\n",
    "        break\n",
    "\n",
    "sample_train_loop(ds, df_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference speed check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8803355693817139, 0.13409948348999023, 0.07209157943725586, 0.0687258243560791, 0.07109665870666504]\n",
      "0.2452698230743408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "import lazycats.np as catnp\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "_LABEL_TYPE = 'majmin'\n",
    "_CHROMA_NUM_FEATS = 24\n",
    "\n",
    "inf_model = init_bilstm_crf_model(base_linear_units=32)\n",
    "inf_times = []\n",
    "\n",
    "for _id in tqdm(test_ids):\n",
    "#for _id in test_ids:\n",
    "    chroma_vectors, chord_labels = dataloader.get_chord_features_and_labels(_id, label_type=_LABEL_TYPE)\n",
    "    assert(chroma_vectors.shape[-1] == _CHROMA_NUM_FEATS)\n",
    "    chordseq_vectors = catnp.divide_to_subsequences(chroma_vectors, sub_len=_SEQ_LEN)\n",
    "    \n",
    "    #print(chordseq_vectors.shape)\n",
    "    st = time.time()\n",
    "    pred_labels, _, _, _ = inf_model.predict(chordseq_vectors, batch_size=32)\n",
    "    inf_times.append(time.time() - st)\n",
    "    #print(pred_labels.shape)\n",
    "    \n",
    "print(inf_times)\n",
    "print(np.mean(inf_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LSTM size | Avg. Inference Time (full song) | Max |\n",
    "|--|--|--|\n",
    "| 32 | 0.23s | 0.86s |\n",
    "| 256 | 0.43s | 0.96s |\n",
    "| 512 | 0.95s | 1.73s |\n",
    "| 1024 | 1.86 | 3.71s |\n",
    "| 2048 | 6.04s | 12.85s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow_addons/text/crf.py:546: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  \"CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\"\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  return py_builtins.overload_of(f)(*args)\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  return py_builtins.overload_of(f)(*args)\n",
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow_addons/text/crf.py:546: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  \"CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\"\n",
      "WARNING:absl:Found untraced functions such as dense_17_layer_call_fn, dense_17_layer_call_and_return_conditional_losses, lstm_cell_52_layer_call_fn, lstm_cell_52_layer_call_and_return_conditional_losses, lstm_cell_53_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/chroma-seq-bilstm-crf-test/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/chroma-seq-bilstm-crf-test/assets\n"
     ]
    }
   ],
   "source": [
    "_CKPT_PATH = 'models/chroma-seq-bilstm-crf-test'\n",
    "save_model = init_bilstm_crf_model(base_linear_units=512)\n",
    "save_preds, _, _, _ = save_model.predict(chordseq_vectors, batch_size=32) # to get shape for serialization\n",
    "save_model.save(_CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tkeras_metadata.pb  saved_model.pb  variables\r\n"
     ]
    }
   ],
   "source": [
    "!ls {_CKPT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_with_crf_loss_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_15 (Functional)        [(None, 64), (None, 64, 2 2225852   \n",
      "=================================================================\n",
      "Total params: 2,225,852\n",
      "Trainable params: 2,225,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "load_model = keras.models.load_model(_CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_with_crf_loss_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_15 (Functional)        [(None, 64), (None, 64, 2 2225852   \n",
      "=================================================================\n",
      "Total params: 2,225,852\n",
      "Trainable params: 2,225,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fae31cedea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fae31cedea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "load_preds, _, _, _ = load_model.predict(chordseq_vectors, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all(save_preds == load_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated tuning & tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R /content/drive/MyDrive/colab-handover/autochord/guild-env-colab ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>operation</th>\n",
       "      <th>started</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty RunsDataFrame\n",
       "Columns: [run, operation, started, status, label]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "GUILD_HOME = 'guild-env/chroma-seq-bilstm-crf' # \"guild-env-colab/chroma-seq-bilstm-crf\"\n",
    "DELETE_RUNS_ON_INIT = False\n",
    "import guild.ipy as guild\n",
    "guild.set_guild_home(GUILD_HOME)\n",
    "\n",
    "if DELETE_RUNS_ON_INIT:\n",
    "    deleted = guild.runs().delete(permanent=True)\n",
    "    print(\"Deleted %i run(s)\" % len(deleted))\n",
    "else:\n",
    "    display(guild.runs().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPOCHS = 5\n",
    "_TRAIN = None\n",
    "_VAL = None\n",
    "\n",
    "# function for guild tracking\n",
    "def hpset_trainloop(hd=256, dp=0.6, opt='adam', lr=0.001, bs=512, si=0):\n",
    "    '''\n",
    "    Train loop with a specific set of hyperparams\n",
    "    \n",
    "    hd: hidden dim base size\n",
    "    dp: dropout rate\n",
    "    opt: optimizer, lr: learning rate\n",
    "    bs: batch size\n",
    "    si: CV split index\n",
    "    '''\n",
    "    tf.random.set_seed(_SEED)\n",
    "    train = _TRAIN\n",
    "    val = _VAL\n",
    "    if (not train) or (not val):\n",
    "        raise Exception(\"Missing data!\")\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                   .take(100) \\\n",
    "                                   .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                   .batch(bs)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                 .take(100) \\\n",
    "                                 .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                 .batch(bs)\n",
    "\n",
    "    assert(train.feats.shape[-1] == val.feats.shape[-1])\n",
    "\n",
    "    model = init_bilstm_crf_model(base_linear_units=hd, dropout=dp, opt=opt, lr=lr)\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS, verbose=0)\n",
    "    \n",
    "    # get acc\n",
    "    preds, _, _, _ = model.predict(val_split.feats, batch_size=_BATCH_SIZE)\n",
    "    acc = accuracy_score(val_split.labels.flatten(), preds.flatten())\n",
    "    \n",
    "    best_epoch = np.argmin(history.history['val_crf_loss'])\n",
    "    best_loss = history.history['val_crf_loss'][best_epoch]\n",
    "    train_loss = history.history['crf_loss'][best_epoch]\n",
    "    \n",
    "    # output metrics\n",
    "    print(f\"BE: {best_epoch+1}\")\n",
    "    print(f\"BL: {best_loss}\")\n",
    "    print(f\"TL: {train_loss}\")\n",
    "    print(f\"VA: {acc}\")\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning loop\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "_REF_IDXS = df_idxs\n",
    "\n",
    "def tuning_loop(hparams):\n",
    "    global _TRAIN\n",
    "    global _VAL\n",
    "    global _REF_IDXS\n",
    "    \n",
    "    print(hparams)\n",
    "\n",
    "    avg_acc = 0.0\n",
    "    num_runs = 0\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split(_REF_IDXS)):\n",
    "        _TRAIN = train\n",
    "        _VAL = val\n",
    "        run, acc = guild.run(hpset_trainloop,\n",
    "                             hd=int(hparams['base_hidden_dim']),\n",
    "                             dp=hparams['drop_rate'],\n",
    "                             opt=hparams['opt'],\n",
    "                             lr=hparams['lr'], \n",
    "                             bs=int(hparams['batch_size']),\n",
    "                             si=cv_ix)\n",
    "        \n",
    "        num_runs += 1\n",
    "        # if hyperparams fail miserably on one split,\n",
    "        # no need to check other splits\n",
    "        if acc < 0.5:\n",
    "            return 1.0\n",
    "            \n",
    "        avg_acc += acc\n",
    "    \n",
    "        if cv_ix == 0: # limit to try multiple config\n",
    "            break\n",
    "    \n",
    "    avg_acc /= num_runs\n",
    "    return (1-avg_acc) # since we're using fmin\n",
    "\n",
    "hparams = {\n",
    "    'base_hidden_dim': hp.choice('base_hidden_dim', [256, 512]),\n",
    "    'drop_rate': hp.choice('drop_rate', [0.5, 0.3, 0.1]),\n",
    "    'opt': hp.choice('opt', ['adam']),\n",
    "    'lr': hp.choice('lr', [1e-3, 3e-4, 1e-4]),\n",
    "    'batch_size': hp.choice('batch_size', [64]),\n",
    "}\n",
    "\n",
    "best = fmin(tuning_loop, hparams, algo=tpe.suggest, max_evals=6)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R guild-env-colab /content/drive/MyDrive/colab-handover/autochord/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bs</th>\n",
       "      <th>dp</th>\n",
       "      <th>hd</th>\n",
       "      <th>lr</th>\n",
       "      <th>opt</th>\n",
       "      <th>si</th>\n",
       "      <th>BE</th>\n",
       "      <th>VA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bs   dp   hd      lr   opt  si   BE       VA\n",
       "9   256  0.6  256  0.0003  adam   0  2.0  0.52030\n",
       "12  512  0.3  256  0.0003  adam   2  2.0  0.52078\n",
       "17  512  0.3  512  0.0003  adam   2  1.0  0.52138\n",
       "36  256  0.5  256  0.0001  adam   3  2.0  0.52239\n",
       "37  256  0.5  256  0.0001  adam   2  1.0  0.52428\n",
       "39  256  0.5  256  0.0001  adam   0  2.0  0.52686\n",
       "51  256  0.5  256  0.0003  adam   0  1.0  0.52050\n",
       "53  256  0.5  256  0.0001  adam   0  2.0  0.52666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = guild.runs()\n",
    "df_exps = runs.compare()\n",
    "\n",
    "_COMPARE_COLS = ['bs','dp','hd','lr','opt','si','BE','TL','BL','VA']\n",
    "comps = df_exps[_COMPARE_COLS]\n",
    "#comps[comps.VA > 0.7]\n",
    "comps[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved model - Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\n",
      "  return py_builtins.overload_of(f)(*args)\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "_CKPT_PATH = 'models/chroma-seq-bilstm-crf-0-base'\n",
    "load_model = keras.models.load_model(_CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 64, 24)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 64, 1024)          2199552   \n",
      "_________________________________________________________________\n",
      "crf_11 (CRF)                 [(None, 64), (None, 64, 2 26300     \n",
      "=================================================================\n",
      "Total params: 2,225,852\n",
      "Trainable params: 2,225,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.saving.saved_model.load.ModelWithCRFLoss"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 64, 24)]          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 64, 1024)          2199552   \n",
      "_________________________________________________________________\n",
      "crf_11 (Addons>CRF)          [(None, 64), (None, 64, 2 26300     \n",
      "=================================================================\n",
      "Total params: 2,225,852\n",
      "Trainable params: 2,225,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model.base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_preds, _, _, _ = load_model.predict(chordseq_vectors, batch_size=32) # to get shape for serialization\n",
    "#load_model.base_model.save('models/chroma-seq-bilstm-crf-0-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  1,  1,  1],\n",
       "       [ 8,  8,  8, ..., 13, 13, 13],\n",
       "       [13, 13, 13, ..., 13, 13, 13],\n",
       "       ...,\n",
       "       [ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
