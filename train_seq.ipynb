{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset\n",
    "import pandas as pd\n",
    "base_dir = 'data/McGill-Billboard'\n",
    "data_index = 'billboard-2.0-manychords.csv'\n",
    "\n",
    "df_songs = pd.read_csv(f'{base_dir}/{data_index}')\n",
    "df_songs.set_index('id', inplace=True)\n",
    "len(df_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>no_chord_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I Don't Mind</td>\n",
       "      <td>James Brown</td>\n",
       "      <td>0.049747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You've Got A Friend</td>\n",
       "      <td>Roberta Flack,Donny Hathaway</td>\n",
       "      <td>0.050770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Rose</td>\n",
       "      <td>Bette Midler</td>\n",
       "      <td>0.117244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                        artist  no_chord_percent\n",
       "id                                                                     \n",
       "3          I Don't Mind                   James Brown          0.049747\n",
       "4   You've Got A Friend  Roberta Flack,Donny Hathaway          0.050770\n",
       "6              The Rose                  Bette Midler          0.117244"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = [1289, 736, 637, 270, 18] # songs to exclude for testing\n",
    "df_dataset = df_songs.drop(index=test_ids)\n",
    "len(df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1167,    6,  986,  227,  743,  568,  107,  181,   27,  793])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "_SEED = 0\n",
    "\n",
    "df_idxs = np.array(df_dataset.index.values)\n",
    "rng = np.random.default_rng(_SEED)\n",
    "rng.shuffle(df_idxs)\n",
    "\n",
    "df_idxs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sequence data.\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "from dataloader import ChromaSequenceDataset\n",
    "from importlib import reload\n",
    "reload(dataloader)\n",
    "\n",
    "_LABEL_TYPE = 'majmin'\n",
    "_SEQ_LEN = 64\n",
    "\n",
    "pre_computed_seq = f'data/chordseq/{_LABEL_TYPE}_{_SEQ_LEN}.pkl'\n",
    "ds = ChromaSequenceDataset(pre_computed_sequence=pre_computed_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((43541, 64, 24), (43541, 64)) ((6882, 64, 24), (6882, 64))\n",
      "((43575, 64, 24), (43575, 64)) ((6848, 64, 24), (6848, 64))\n",
      "((43448, 64, 24), (43448, 64)) ((6975, 64, 24), (6975, 64))\n",
      "((43485, 64, 24), (43485, 64)) ((6938, 64, 24), (6938, 64))\n",
      "((42843, 64, 24), (42843, 64)) ((7580, 64, 24), (7580, 64))\n"
     ]
    }
   ],
   "source": [
    "for train_split, val_split in ds.get_next_cv_split(df_idxs):\n",
    "    print(train_split.shape, val_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt\n",
    "!pip install guildai # restart after install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab prep\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/colab-handover/autochord/* ./\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataloader import SimpleChromaDataset\n",
    "\n",
    "# ds = SimpleChromaDataset(feat_label_files=('01_all_chroma_vectors.npy',\n",
    "#                                            '01_all_chord_labels.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def K_plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = tfa.layers.CRF(units=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import _CHROMA_FEAT_NAMES, _MAJMIN_CLASSES\n",
    "\n",
    "_SEED = 0\n",
    "_EPOCHS = 2 #10\n",
    "_BATCH_SIZE = 2 #512\n",
    "_SEQ_LEN = 64\n",
    "_CKPT_PATH = 'models/chroma-seq-bilstm-crf-{cv}'\n",
    "\n",
    "def init_bilstm_crf_model(base_linear_units=256, dropout=0.6, opt='adam', lr=0.01):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(_SEQ_LEN, len(_CHROMA_FEAT_NAMES),)),\n",
    "        layers.Bidirectional(\n",
    "            layers.LSTM(units=base_linear_units, dropout=dropout,\n",
    "                        stateful=False, return_sequences=False),\n",
    "            merge_mode='concat'\n",
    "        ),\n",
    "#         layers.TimeDistributed(\n",
    "#             layers.Dense(units=len(_MAJMIN_CLASSES), activation='softmax')\n",
    "#         )\n",
    "        tfa.layers.CRF(units=len(_MAJMIN_CLASSES))\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def sample_train_loop(ds):\n",
    "    # cross validation loop\n",
    "    tf.random.set_seed(_SEED)\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split()):\n",
    "        print(f'----------- CV{cv_ix+1} -----------')\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                       .take(100) \\\n",
    "                                       .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                       .batch(_BATCH_SIZE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                     .take(100) \\\n",
    "                                     .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                     .batch(_BATCH_SIZE)\n",
    "\n",
    "        print(f'Num train: {len(train)}, Num val: {len(val)}')\n",
    "        assert(train.feats.shape[-1] == val.feats.shape[-1])\n",
    "        print(f'Input features: {train.feats.shape[-1]}, Num classes: {ds.n_class}')\n",
    "        \n",
    "        model = init_simple_model()\n",
    "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS)\n",
    "\n",
    "        # get F1 score\n",
    "        pred_chord_ixs = np.argmax(model.predict(val.feats, batch_size=_BATCH_SIZE), axis=1)\n",
    "        print(f\"val_fscore: {f1_score(y_true=val.labels, y_pred=pred_chord_ixs, average='macro')}\")\n",
    "        K_plot_loss(history)\n",
    "\n",
    "        model.save(_CKPT_PATH.format(cv=cv_ix))\n",
    "\n",
    "        break\n",
    "\n",
    "sample_train_loop(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual tracking**\n",
    "\n",
    "1. 256, 0.6, `Adam (0.01)` - `val loss: 3.2, val acc: 12.98%`\n",
    "2. 1024, 0.6, `Adam (0.001)` - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated tuning & tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R /content/drive/MyDrive/colab-handover/autochord/guild-env-colab ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>operation</th>\n",
       "      <th>started</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ff8c9ad6</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:53:50</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d15565c</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:52:48</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856f7a7f</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:51:46</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66da07ec</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:50:44</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f21924d</td>\n",
       "      <td>hpset_trainloop()</td>\n",
       "      <td>2021-05-23 05:49:43</td>\n",
       "      <td>completed</td>\n",
       "      <td>bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run          operation             started     status  \\\n",
       "0  ff8c9ad6  hpset_trainloop() 2021-05-23 05:53:50  completed   \n",
       "1  5d15565c  hpset_trainloop() 2021-05-23 05:52:48  completed   \n",
       "2  856f7a7f  hpset_trainloop() 2021-05-23 05:51:46  completed   \n",
       "3  66da07ec  hpset_trainloop() 2021-05-23 05:50:44  completed   \n",
       "4  6f21924d  hpset_trainloop() 2021-05-23 05:49:43  completed   \n",
       "\n",
       "                                         label  \n",
       "0  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=4  \n",
       "1  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=3  \n",
       "2  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=2  \n",
       "3  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=1  \n",
       "4  bs=512 dp=0.6 hd=256 lr=0.001 opt=adam si=0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "GUILD_HOME = 'guild-env/simple-chroma' # \"guild-env-colab/simple-chroma\"\n",
    "DELETE_RUNS_ON_INIT = False\n",
    "import guild.ipy as guild\n",
    "guild.set_guild_home(GUILD_HOME)\n",
    "\n",
    "if DELETE_RUNS_ON_INIT:\n",
    "    deleted = guild.runs().delete(permanent=True)\n",
    "    print(\"Deleted %i run(s)\" % len(deleted))\n",
    "else:\n",
    "    display(guild.runs().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPOCHS = 5\n",
    "_TRAIN = None\n",
    "_VAL = None\n",
    "\n",
    "# function for guild tracking\n",
    "def hpset_trainloop(hd=256, dp=0.6, opt='adam', lr=0.001, bs=512, si=0):\n",
    "    '''\n",
    "    Train loop with a specific set of hyperparams\n",
    "    \n",
    "    hd: hidden dim base size\n",
    "    dp: dropout rate\n",
    "    opt: optimizer, lr: learning rate\n",
    "    bs: batch size\n",
    "    si: CV split index\n",
    "    '''\n",
    "    tf.random.set_seed(_SEED)\n",
    "    train = _TRAIN\n",
    "    val = _VAL\n",
    "    if (not train) or (not val):\n",
    "        raise Exception(\"Missing data!\")\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train.feats, train.labels)) \\\n",
    "                                   .take(100) \\\n",
    "                                   .shuffle(buffer_size=len(train), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                   .batch(bs)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val.feats, val.labels)) \\\n",
    "                                 .take(100) \\\n",
    "                                 .shuffle(buffer_size=len(val), seed=_SEED, reshuffle_each_iteration=True) \\\n",
    "                                 .batch(bs)\n",
    "\n",
    "    assert(train.feats.shape[-1] == val.feats.shape[-1])\n",
    "\n",
    "    model = init_simple_model(base_linear_units=hd, dropout=dp, opt=opt, lr=lr)\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=_EPOCHS, verbose=0)\n",
    "    \n",
    "    best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "    best_acc = history.history['val_accuracy'][best_epoch]\n",
    "    \n",
    "    # output metrics\n",
    "    print(f\"BE: {best_epoch+1}\")\n",
    "    print(f\"VA: {best_acc}\")\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning loop\n",
    "from hyperopt import hp, tpe, fmin\n",
    "\n",
    "def tuning_loop(hparams):\n",
    "    global _TRAIN\n",
    "    global _VAL\n",
    "    \n",
    "    print(hparams)\n",
    "\n",
    "    avg_acc = 0.0\n",
    "    num_runs = 0\n",
    "    for cv_ix, (train, val) in enumerate(ds.get_next_cv_split()):\n",
    "        _TRAIN = train\n",
    "        _VAL = val\n",
    "        run, acc = guild.run(hpset_trainloop,\n",
    "                             hd=int(hparams['base_hidden_dim']),\n",
    "                             dp=hparams['drop_rate'],\n",
    "                           opt=hparams['opt'],\n",
    "                             lr=hparams['lr'], \n",
    "                             bs=int(hparams['batch_size']),\n",
    "                             si=cv_ix)\n",
    "        \n",
    "        num_runs += 1\n",
    "        # if hyperparams fail miserably on one split,\n",
    "        # no need to check other splits\n",
    "        if acc < 0.5:\n",
    "            return 1.0\n",
    "            \n",
    "        avg_acc += acc\n",
    "    \n",
    "    avg_acc /= num_runs\n",
    "    return (1-avg_acc) # since we're using fmin\n",
    "\n",
    "hparams = {\n",
    "    'base_hidden_dim': hp.choice('base_hidden_dim', [256, 512, 1024]),\n",
    "    'drop_rate': hp.choice('drop_rate', [0.9, 0.7, 0.5, 0.3]),\n",
    "    'opt': hp.choice('opt', ['adam']),\n",
    "    'lr': hp.choice('lr', [1e-2, 1e-3, 3e-4, 1e-4]),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n",
    "}\n",
    "\n",
    "best = fmin(tuning_loop, hparams, algo=tpe.suggest, max_evals=1)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "!cp -R guild-env-colab /content/drive/MyDrive/colab-handover/autochord/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bs</th>\n",
       "      <th>dp</th>\n",
       "      <th>hd</th>\n",
       "      <th>lr</th>\n",
       "      <th>opt</th>\n",
       "      <th>si</th>\n",
       "      <th>BE</th>\n",
       "      <th>VA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.52666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bs   dp   hd      lr   opt  si   BE       VA\n",
       "9   256  0.6  256  0.0003  adam   0  2.0  0.52030\n",
       "12  512  0.3  256  0.0003  adam   2  2.0  0.52078\n",
       "17  512  0.3  512  0.0003  adam   2  1.0  0.52138\n",
       "36  256  0.5  256  0.0001  adam   3  2.0  0.52239\n",
       "37  256  0.5  256  0.0001  adam   2  1.0  0.52428\n",
       "39  256  0.5  256  0.0001  adam   0  2.0  0.52686\n",
       "51  256  0.5  256  0.0003  adam   0  1.0  0.52050\n",
       "53  256  0.5  256  0.0001  adam   0  2.0  0.52666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = guild.runs()\n",
    "df_exps = runs.compare()\n",
    "\n",
    "_COMPARE_COLS = ['bs','dp','hd','lr','opt','si','BE','VA']\n",
    "comps = df_exps[_COMPARE_COLS][:65]\n",
    "comps[comps.VA > 0.52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# try limiting class\n",
    "ds.chroma_vectors = np.load('01_all_chroma_vectors.npy')\n",
    "ds.chord_labels = np.load('01_all_chord_labels.npy')\n",
    "filt = np.isin(ds.chord_labels, (0,1))\n",
    "ds.chroma_vectors = ds.chroma_vectors[filt]\n",
    "ds.chord_labels = ds.chord_labels[filt]\n",
    "ds.classes = set(ds.chord_labels)\n",
    "ds.n_class = len(ds.classes)\n",
    "print('Loaded features and labels.')\n",
    "ds.train_split, ds.val_splits, ds.test_split = ds.get_splits()\n",
    "print('Split into train, val, test.')\n",
    "print(ds.n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.198482  0.        0.        0.635556  0.741292  1.0043    0.81444\n",
      " 0.0292819 0.141189  0.80793   0.91015   0.823603  1.22066   0.0969013\n",
      " 0.197437  0.860228  1.16515   1.13561   0.42842   0.112475  1.49297\n",
      " 0.556156  0.562561  0.864485 ] 0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 17\n"
     ]
    }
   ],
   "source": [
    "print(ds.chroma_vectors[0], ds.chord_labels[0])\n",
    "print(ds.chroma_vectors[-113], ds.chord_labels[-113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.32049295, 0.24610202, 0.28693406, 0.25687285, 0.20151652,\n",
       "       0.29747371, 0.20591433, 0.27151966, 0.22509008, 0.21612551,\n",
       "       0.26522816, 0.21338926, 0.7405679 , 0.48997662, 0.60600057,\n",
       "       0.60080249, 0.48543003, 0.73010563, 0.44549839, 0.73231232,\n",
       "       0.53258909, 0.54258336, 0.6778894 , 0.48055285])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = [ds.chord_labels == 0]\n",
    "np.mean(ds.chroma_vectors[filt], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.20761943, 0.14172344, 0.25146699, 1.23340365, 0.1735976 ,\n",
       "       0.17857491, 0.14191071, 0.30587265, 0.20928596, 0.19817245,\n",
       "       0.54753261, 0.16978452, 0.48747069, 0.36887956, 0.55286642,\n",
       "       2.05746208, 0.21877638, 0.64896599, 0.25239646, 1.45968816,\n",
       "       0.40032339, 0.2984598 , 1.69132596, 0.2568249 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = [ds.chord_labels == 1]\n",
    "np.mean(ds.chroma_vectors[filt], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [np.sum(ds.chroma_vectors, axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cjbayron/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 49874,\n",
       "         2: 203,\n",
       "         8: 537,\n",
       "         22: 150,\n",
       "         13: 51,\n",
       "         6: 464,\n",
       "         7: 249,\n",
       "         12: 330,\n",
       "         9: 192,\n",
       "         4: 141,\n",
       "         24: 34,\n",
       "         1: 399,\n",
       "         17: 97,\n",
       "         15: 244,\n",
       "         10: 434,\n",
       "         5: 547,\n",
       "         14: 77,\n",
       "         3: 414,\n",
       "         11: 269,\n",
       "         20: 80,\n",
       "         18: 140,\n",
       "         23: 21,\n",
       "         16: 141,\n",
       "         19: 29,\n",
       "         21: 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ds.chord_labels[filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03958175703883171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               6400      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                6425      \n",
      "=================================================================\n",
      "Total params: 538,393\n",
      "Trainable params: 538,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "m = tf.keras.models.load_model(_CKPT_PATH.format(cv=0))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "# add tuning\n",
    "# mind the seeding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
